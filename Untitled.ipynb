{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, No: string, year: string, month: string, day: string, hour: string, season: string, pm: string, DEWP: string, HUMI: string, PRES: string, TEMP: string, cbwd: string, Iws: string, precipitation: string, Iprec: string, air quality level: string]\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('operations').getOrCreate()\n",
    "x = spark.read.csv('data.csv', inferSchema=True, header=True)\n",
    "print(x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "  inputCols=['year',\n",
    "             'day',\n",
    "             'month',\n",
    "             'hour',\n",
    "             'season',\n",
    "             'DEWP',\n",
    "             'HUMI',\n",
    "             'PRES',\n",
    "             'TEMP',\n",
    "             'Iws',\n",
    "             'precipitation',\n",
    "             'Iprec',\n",
    "             'cbwd'],\n",
    "              outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"air quality level\", outputCol=\"air quality level index\")\n",
    "output_fixed = indexer.fit(output).transform(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output_fixed.select(\"features\",\"air quality level index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = final_data.randomSplit([0.8,0.2])\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,GBTClassifier,RandomForestClassifier\n",
    "DecisionTreeClassifier,RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "dtc = DecisionTreeClassifier(labelCol='air quality level index',featuresCol='features',\n",
    "                             impurity='entropy',maxBins=50,maxDepth=30)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC\n",
      "0.6635128829377156\n",
      "+--------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|            features|air quality level index|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|[2013.0,4.0,22.0,...|                    0.0|[0.0,0.0,7.0,0.0,...|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "|[2013.0,4.0,26.0,...|                    1.0|[0.0,1.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[2013.0,4.0,26.0,...|                    1.0|[0.0,9.0,0.0,0.0,...|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[2013.0,4.0,27.0,...|                    3.0|[0.0,0.0,0.0,6.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,4.0,27.0,...|                    3.0|[0.0,0.0,0.0,2.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,5.0,2.0,1...|                    2.0|[0.0,0.0,4.0,0.0,...|[0.0,0.0,1.0,0.0,...|       2.0|\n",
      "|[2013.0,5.0,3.0,2...|                    0.0|[12.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,3.0,2...|                    0.0|[5.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,5.0,3...|                    0.0|[11.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,5.0,4...|                    0.0|[11.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,5.0,8...|                    0.0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,5.0,1...|                    5.0|[0.0,0.0,0.0,1.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,5.0,6.0,6...|                    3.0|[6.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,6.0,1...|                    3.0|[0.0,0.0,0.0,5.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "|[2013.0,5.0,6.0,2...|                    3.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       5.0|\n",
      "|[2013.0,5.0,6.0,2...|                    5.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       4.0|\n",
      "|[2013.0,5.0,7.0,0...|                    5.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       5.0|\n",
      "|[2013.0,5.0,7.0,1...|                    0.0|[2.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,7.0,1...|                    0.0|[16.0,0.0,0.0,0.0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|[2013.0,5.0,8.0,6...|                    0.0|[0.0,0.0,0.0,5.0,...|[0.0,0.0,0.0,1.0,...|       3.0|\n",
      "+--------------------+-----------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol = 'air quality level index')\n",
    "print(\"DTC\")\n",
    "print(my_binary_eval.evaluate(dtc_predictions))\n",
    "dtc_predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <object repr() failed>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 76, in __del__\n",
      "    SparkContext._active_spark_context._gateway.detach(self._java_obj)\n",
      "AttributeError: 'BinaryClassificationEvaluator' object has no attribute '_java_obj'\n",
      "Exception ignored in: <object repr() failed>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\", line 76, in __del__\n",
      "    SparkContext._active_spark_context._gateway.detach(self._java_obj)\n",
      "AttributeError: 'RandomForestClassifier' object has no attribute '_java_obj'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC\n",
      "0.6833296743337084\n",
      "+--------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|            features|air quality level index|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|[2013.0,4.0,23.0,...|                    3.0|[10.7571951069179...|[0.53785975534589...|       0.0|\n",
      "|[2013.0,4.0,25.0,...|                    2.0|[9.77676008468955...|[0.48883800423447...|       0.0|\n",
      "|[2013.0,4.0,25.0,...|                    1.0|[6.99244455100718...|[0.34962222755035...|       0.0|\n",
      "|[2013.0,4.0,26.0,...|                    2.0|[10.9858152021720...|[0.54929076010860...|       0.0|\n",
      "|[2013.0,4.0,26.0,...|                    1.0|[8.01550027697920...|[0.40077501384896...|       0.0|\n",
      "|[2013.0,4.0,26.0,...|                    1.0|[5.10977586105501...|[0.25548879305275...|       1.0|\n",
      "|[2013.0,4.0,27.0,...|                    3.0|[10.9428737138920...|[0.54714368569460...|       0.0|\n",
      "|[2013.0,4.0,27.0,...|                    3.0|[11.0545574221402...|[0.55272787110701...|       0.0|\n",
      "|[2013.0,4.0,27.0,...|                    0.0|[11.1308699902246...|[0.55654349951123...|       0.0|\n",
      "|[2013.0,5.0,3.0,2...|                    0.0|[9.30703954821105...|[0.46535197741055...|       0.0|\n",
      "|[2013.0,5.0,4.0,3...|                    3.0|[9.87795397597371...|[0.49389769879868...|       0.0|\n",
      "|[2013.0,5.0,4.0,9...|                    3.0|[9.62672051066910...|[0.48133602553345...|       0.0|\n",
      "|[2013.0,5.0,4.0,1...|                    2.0|[8.39887685490882...|[0.41994384274544...|       0.0|\n",
      "|[2013.0,5.0,4.0,1...|                    0.0|[8.39887685490882...|[0.41994384274544...|       0.0|\n",
      "|[2013.0,5.0,4.0,1...|                    0.0|[8.39887685490882...|[0.41994384274544...|       0.0|\n",
      "|[2013.0,5.0,4.0,2...|                    2.0|[8.82320034391449...|[0.44116001719572...|       0.0|\n",
      "|[2013.0,5.0,5.0,4...|                    0.0|[10.1746824444270...|[0.50873412222135...|       0.0|\n",
      "|[2013.0,5.0,5.0,1...|                    0.0|[9.02121872341751...|[0.45106093617087...|       0.0|\n",
      "|[2013.0,5.0,5.0,1...|                    0.0|[8.69350295180813...|[0.43467514759040...|       0.0|\n",
      "|[2013.0,5.0,5.0,1...|                    0.0|[8.38833895072383...|[0.41941694753619...|       0.0|\n",
      "+--------------------+-----------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(labelCol='air quality level index',featuresCol='features')\n",
    "rfc_model = rfc.fit(train_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "print(\"RFC\")\n",
    "print(my_binary_eval.evaluate(rfc_predictions))\n",
    "rfc_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results!\n",
      "----------------------------------------\n",
      "A single decision tree has an accuracy of: 62.48%\n",
      "----------------------------------------\n",
      "A random forest ensemble has an accuracy of: 49.28%\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"air quality level index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dtc_acc = acc_evaluator.evaluate(dtc_predictions)\n",
    "rfc_acc = acc_evaluator.evaluate(rfc_predictions)\n",
    "print(\"Here are the results!\")\n",
    "print('-'*40)\n",
    "print('A single decision tree has an accuracy of: {0:2.2f}%'.format(dtc_acc*100))\n",
    "print('-'*40)\n",
    "print('A random forest ensemble has an accuracy of: {0:2.2f}%'.format(rfc_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall value = 0.6247723132969034\n",
      "F1 score = 0.6247723132969034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "results = dtc_predictions.select(['prediction','air quality level index'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "recall = metrics.recall()\n",
    "flScore =metrics.fMeasure()\n",
    "print(\"Recall value = %s\" % recall)\n",
    "print(\"F1 score = %s\" % flScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:249: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall value = 0.49284413218839446\n",
      "F1 score = 0.49284413218839446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/spark-2.1.1-bin-hadoop2.7/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "results = rfc_predictions.select(['prediction','air quality level index'])\n",
    "predictionAndLabels=results.rdd\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "recall = metrics.recall()\n",
    "flScore =metrics.fMeasure()\n",
    "print(\"Recall value = %s\" % recall)\n",
    "print(\"F1 score = %s\" % flScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
